# Instructions

During you interaction with the user, if you find anything reusable in this project (e.g. version of a library, model name), especially about a fix to a mistake you made or a correction you received, you should take note in the `Lessons` section in the `.cursorrules` file so you will not make the same mistake again. 

You should also use the `.cursorrules` file as a scratchpad to organize your thoughts. Especially when you receive a new task, you should first review the content of the scratchpad, clear old different task if necessary, first explain the task, and plan the steps you need to take to complete the task. You can use todo markers to indicate the progress, e.g.
[X] Task 1
[ ] Task 2
Also update the progress of the task in the Scratchpad when you finish a subtask.
Especially when you finished a milestone, it will help to improve your depth of task accomplishment to use the scratchpad to reflect and plan.
The goal is to help you maintain a big picture as well as the progress of the task. Always refer to the Scratchpad when you plan the next step.



# Lessons

## User Specified Lessons

- You have a python venv in ./py310.
- Include info useful for debugging in the program output.
- Read the file before you try to edit it.
- Use LLM to perform flexible text understanding tasks. First test on a few files. After success, make it parallel.

## Cursor learned

- For website image paths, always use the correct relative path (e.g., 'images/filename.png') and ensure the images directory exists
- For search results, ensure proper handling of different character encodings (UTF-8) for international queries
- Add debug information to stderr while keeping the main output clean in stdout for better pipeline integration
- When using seaborn styles in matplotlib, use 'seaborn-v0_8' instead of 'seaborn' as the style name due to recent seaborn version changes
- AutoGen Studio FunctionTool configurations require exact JSON structure matching the Studio-generated format, including specific required fields like model_client_stream, reflect_on_tool_use, tool_call_summary_format, metadata, and proper component descriptions
- Natural language rules in agent system messages are much more reliable than complex tools for workflow orchestration
- AutoGen orchestrator selector_prompt needs very explicit instructions to follow Rule Agent guidance - vague prompts cause routing failures
- AutoGen orchestrators can get stuck in loops if selector prompt doesn't clearly define when to select Rule_agent vs when to select the suggested business agent
- AutoGen SelectorGroupChat selector_prompt must use proper variables {history}, {roles}, {participants} to access conversation context - without these the orchestrator only sees its system prompt
- UserProxyAgent in AutoGen Studio is for user input collection only - it should NOT have a function_map, just name and description fields
- **{history} parameter only works for selector agents/orchestrators, NOT for individual agent system messages**
- **Individual agents must access conversation history through the messages parameter in their reply functions or their own conversation tracking**
- **AutoGen agents with tools can get stuck in repetitive tool calling loops if system messages don't explicitly prohibit duplicate calls and if context windows are too small**

# Scratchpad

## Current Task: AutoGen Studio Rule Agent Natural Language Implementation

### Problem RESOLVED ✅
[X] Replaced complex `suggest_next_step` tool with natural language workflow rules
[X] Updated Rule Agent system message with clear, structured rules
[X] Removed the Rule Agent tool file and dependencies
[X] Regenerated combined orchestrator with the new approach
[X] Enabled `reflect_on_tool_use: true` for all agents
[X] Fixed orchestrator selector prompt to properly follow Rule Agent guidance
[X] Resolved orchestrator loop issue with speaker-based selection logic
[X] Fixed critical issue: orchestrator wasn't receiving conversation history
[X] Updated workflow rules to new streamlined sequential flow
[X] Implemented Mock Data Injection System
[X] Updated Requests Structure - removed customerId field, added requestor blocks
[X] Renamed Rule Agent to Request Analysis Agent with enhanced capabilities
[X] Fixed tool injection matching logic in combine_tools.py
[X] FIXED JSON SYNTAX VIOLATION - Removed unnecessary function_map from UserProxyAgent
[X] **ENHANCED REQUEST ANALYSIS AGENT** - Now provides comprehensive briefings with request details and specific instructions
[X] **ENHANCED CUSTOMER VERIFICATION AGENT** - Now supports intelligent fuzzy search with confidence scoring
[X] **IDENTIFIED {history} LIMITATION** - {history} parameter only works for orchestrator selector prompts, not individual agent system messages
[X] **FIXED {history} PARAMETER ISSUE** - Removed broken {history} approach from Request Analysis Agent system message

### Current Status: COMPLETE ✅

**Problem RESOLVED:** The Request Analysis Agent repetitive tool calling issue has been fixed by:
- **Added explicit anti-loop rules** to system message preventing duplicate `get_request_details` calls
- **Increased context window** from `tail_size: 1` to `tail_size: 3` for better conversation awareness
- **Added history-first approach** requiring agents to check recent messages before tool calls
- **Implemented strict tool call conditions** with clear criteria for when to use tools

**Previous Issues Also Resolved:**
- **{history} parameter issue** - Removed broken {history} approach from system messages
- **Orchestrator routing reliability** - Implemented HeadAndTailChatCompletionContext with bulletproof selector prompt
- **Function call dependency** - Replaced `generate_routing_output` function requirement with direct JSON format for cleaner responses

**Key Learnings Applied:**
- **{history} only works for selector agents/orchestrators** (GroupChat managers)
- **Individual agents cannot use {history}** in their system messages
- **AutoGen agents need explicit anti-loop protection** in system messages when using tools
- **Context window size matters** for agents to see their own previous actions
- **Simpler approaches often work better** than complex workarounds

### Customer Verification Agent Enhancement Details
**Enhanced Tool Capabilities:**
- **Fuzzy Name Matching**: Uses difflib.SequenceMatcher for similarity scoring
- **Partial SSN Matching**: Handles last 4 digits or full SSN formats
- **Address Component Matching**: Matches individual address parts and partial addresses
- **Confidence Factors**: Detailed breakdown of what contributed to the match score
- **Smart Weighting**: SSN (40%), Name (30%), Address (30%) for balanced assessment

**Enhanced Agent Intelligence:**
- **Search Strategy Selection**: Chooses optimal approach based on available data
- **Confidence Assessment**: Clear guidelines for interpreting match quality
- **Multi-Criteria Fallback**: Tries different combinations if initial search fails
- **Spouse Search Capability**: Can search for spouse if requester not found
- **Quality Standards**: Transparent about uncertainty, recommends manual review when appropriate

**Output Format:**
```json
{
  "verification_result": "verified" | "not_found" | "ambiguous",
  "confidence_percentage": 85,
  "customer_id": "CUST-12345",
  "customer_name": "John Doe",
  "actor": "self" | "spouse",
  "match_details": "SSN exact match; Name exact match",
  "search_strategy_used": "SSN + Name combination",
  "recommendation": "Proceed with high confidence"
}
```

### Request Analysis Agent Enhancement Details
**New Response Format:**
```
## REQUEST ANALYSIS
[Complete request details and current context]

## NEXT AGENT
**Agent:** [Agent name]

## INSTRUCTIONS FOR NEXT AGENT
[Detailed, specific instructions including:
- Key information to verify/process
- Specific documents or data points to examine
- Expected outputs or decisions needed
- Any special considerations or requirements]

## CONTEXT SUMMARY
[Brief summary of workflow progress and what has been completed so far]
```

**Orchestrator Updates:**
- Updated selector prompt to parse agent name from "## NEXT AGENT" section
- Enhanced parsing instructions for the new detailed format

### Status: COMPLETE - Orchestrator Optimization ✅
[X] **FINAL SOLUTION: Simplified Orchestrator + BufferedChatCompletionContext**

#### **Problem Solved:**
- **Issue**: Orchestrator routing unreliably due to conversation history confusion
- **Root Cause**: Full conversation history overwhelming selector prompt decision-making

#### **Two-Part Solution Applied:**

**1. HeadAndTailChatCompletionContext (Smart History Limitation):**
```json
"model_context": {
  "provider": "autogen_core.model_context.HeadAndTailChatCompletionContext",
  "component_type": "chat_completion_context", 
  "config": {
    "head_size": 1,
    "tail_size": 2
  }
}
```

**2. Bulletproof Selector Prompt (Step-by-Step Last Speaker Detection):**
```
STEP 1: Look at the conversation below and find the VERY LAST speaker (scan from bottom up, find the final agent name before a colon).

STEP 2: Apply these rules:
- If the final speaker was NOT 'Request_Analysis_agent' → return 'Request_Analysis_agent'
- If the final speaker WAS 'Request_Analysis_agent' → look for 'next_agent' in their message and return that agent name
```

#### **Why This Architecture Works:**
- **Request Analysis Agent = The Brain**: Makes all routing decisions based on workflow rules
- **Orchestrator = Simple Router**: Just delegates to Request Analysis Agent or follows its guidance
- **HeadAndTailChatCompletionContext**: Keeps initial task (head_size: 1) + last 2 messages (tail_size: 2)
- **Minimal Complexity**: Only 2 rules instead of complex conditional logic

#### **Benefits:**
✅ **Smart History Management**: Preserves initial task context + immediate recent context  
✅ **Eliminates History Confusion**: No overwhelming conversation logs  
✅ **Bulletproof Last Speaker Detection**: Step-by-step instructions prevent parsing errors  
✅ **Simple Logic**: Two-rule orchestrator is easy to debug and maintain  
✅ **Centralized Intelligence**: All workflow logic concentrated in Request Analysis Agent  
✅ **AutoGen Native**: Uses official AutoGen model_context system  
✅ **Scalable**: Easy to modify workflow rules without touching orchestrator  

#### **Critical Fix Applied:**
**Problem Identified from User Log**: Even with history limitation, AutoGen was bundling multiple messages into "Last message" block, making it impossible for the orchestrator to identify the actual last speaker.

**Solution**: Updated selector prompt with explicit STEP 1 and STEP 2 instructions:
- **STEP 1**: "Look at the conversation below and find the VERY LAST speaker (scan from bottom up, find the final agent name before a colon)"
- **STEP 2**: Apply the routing rules

**XML Separator Added**: Wrapped history in `<CONVERSATION_HISTORY>` tags to clearly separate conversation from instructions, preventing confusion when selector prompt instructions appeared to be part of the conversation.

This prevents the LLM from getting confused when multiple agent messages appear in the history block.  

#### **Alternative Buffer Options Available:**
- **BufferedChatCompletionContext**: Keep last N messages only
- **TokenLimitedChatCompletionContext**: Limit by token count instead of message count  
- **UnboundedChatCompletionContext**: Keep all messages (original default)
